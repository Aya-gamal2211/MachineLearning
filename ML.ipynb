{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE381 Introduction to Machine Learning – Spring 2023\n",
    "**Project Description**\n",
    "\n",
    "The data used in this project will help to identify whether a person is going to recover from\n",
    "coronavirus symptoms or not based on some pre‐defined standard symptoms. These\n",
    "symptoms are based on guidelines given by the World Health Organization (WHO).\n",
    "This dataset has daily level information on the number of affected cases, deaths and\n",
    "recovery from 2019 novel coronavirus. Please note that this is a time series data and so the\n",
    "number of cases on any given day is the cumulative number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,  PolynomialFeatures   \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#pip install tensorflow before importing\n",
    "import tensorflow\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('..\\data.csv')\n",
    "# Split the inputs and outputs into separate arrays\n",
    "# x = data[ :, 0]\n",
    "# y = data[:,1]\n",
    "#training_data = data[:70]\n",
    "feature_cols=['location',\t'country' ,\t'gender' ,\t'age' ,\t'vis_wuhan',\t'from_wuhan',\t'symptom1'\t,'symptom2'\t,'symptom3'\t,'symptom4'\t,'symptom5'\t,'symptom6', \t'diff_sym_hos'\n",
    "]\n",
    "x=data[feature_cols]\n",
    "y=data.result\n",
    "# Convert 1-D arrays into 2-D because the commands later will require it\n",
    "# x = np.expand_dims(x, axis=1)\n",
    "# y = np.expand_dims(y, axis=1)\n",
    "# Get 70% of the dataset as the training set. Put the remaining 30% in temporary variables: x_test and y_test.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=3)\n",
    "# Split the 30% subset above into two: one half for cross validation and the other for the test set\n",
    "x_cv, x_test, y_cv, y_test = train_test_split(x_test, y_test, test_size=0.50, random_state=3)\n",
    "#another approach to divide data \n",
    "#train, validate, test = np.split(df.sample(frac=1, random_state=42), #60 training 20 validation 20 test \n",
    "                      # [int(.6*len(df)), int(.8*len(df))]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>vis_wuhan</th>\n",
       "      <th>from_wuhan</th>\n",
       "      <th>symptom1</th>\n",
       "      <th>symptom2</th>\n",
       "      <th>symptom3</th>\n",
       "      <th>symptom4</th>\n",
       "      <th>symptom5</th>\n",
       "      <th>symptom6</th>\n",
       "      <th>diff_sym_hos</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>863.000000</td>\n",
       "      <td>863.000000</td>\n",
       "      <td>863.000000</td>\n",
       "      <td>863.000000</td>\n",
       "      <td>863.000000</td>\n",
       "      <td>863.000000</td>\n",
       "      <td>863.000000</td>\n",
       "      <td>863.00000</td>\n",
       "      <td>863.000000</td>\n",
       "      <td>863.000000</td>\n",
       "      <td>863.000000</td>\n",
       "      <td>863.000000</td>\n",
       "      <td>863.000000</td>\n",
       "      <td>863.000000</td>\n",
       "      <td>863.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>431.000000</td>\n",
       "      <td>76.645423</td>\n",
       "      <td>16.995365</td>\n",
       "      <td>0.849363</td>\n",
       "      <td>49.400000</td>\n",
       "      <td>0.181924</td>\n",
       "      <td>0.107764</td>\n",
       "      <td>12.13905</td>\n",
       "      <td>28.002317</td>\n",
       "      <td>18.298957</td>\n",
       "      <td>11.840093</td>\n",
       "      <td>2.993048</td>\n",
       "      <td>0.998841</td>\n",
       "      <td>0.995365</td>\n",
       "      <td>0.125145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>249.270937</td>\n",
       "      <td>39.200264</td>\n",
       "      <td>7.809951</td>\n",
       "      <td>0.726062</td>\n",
       "      <td>15.079203</td>\n",
       "      <td>0.386005</td>\n",
       "      <td>0.310261</td>\n",
       "      <td>3.99787</td>\n",
       "      <td>7.473231</td>\n",
       "      <td>2.864064</td>\n",
       "      <td>1.183771</td>\n",
       "      <td>0.127251</td>\n",
       "      <td>0.034040</td>\n",
       "      <td>2.358767</td>\n",
       "      <td>0.331075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>215.500000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>431.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>646.500000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>862.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0    location     country      gender         age   vis_wuhan  \\\n",
       "count  863.000000  863.000000  863.000000  863.000000  863.000000  863.000000   \n",
       "mean   431.000000   76.645423   16.995365    0.849363   49.400000    0.181924   \n",
       "std    249.270937   39.200264    7.809951    0.726062   15.079203    0.386005   \n",
       "min      0.000000    0.000000    0.000000    0.000000    2.000000    0.000000   \n",
       "25%    215.500000   45.000000   11.000000    0.000000   40.000000    0.000000   \n",
       "50%    431.000000   87.000000   18.000000    1.000000   49.400000    0.000000   \n",
       "75%    646.500000  110.000000   24.000000    1.000000   57.000000    0.000000   \n",
       "max    862.000000  138.000000   33.000000    2.000000   96.000000    1.000000   \n",
       "\n",
       "       from_wuhan   symptom1    symptom2    symptom3    symptom4    symptom5  \\\n",
       "count  863.000000  863.00000  863.000000  863.000000  863.000000  863.000000   \n",
       "mean     0.107764   12.13905   28.002317   18.298957   11.840093    2.993048   \n",
       "std      0.310261    3.99787    7.473231    2.864064    1.183771    0.127251   \n",
       "min      0.000000    0.00000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000   14.00000   31.000000   19.000000   12.000000    3.000000   \n",
       "50%      0.000000   14.00000   31.000000   19.000000   12.000000    3.000000   \n",
       "75%      0.000000   14.00000   31.000000   19.000000   12.000000    3.000000   \n",
       "max      1.000000   24.00000   31.000000   19.000000   12.000000    3.000000   \n",
       "\n",
       "         symptom6  diff_sym_hos      result  \n",
       "count  863.000000    863.000000  863.000000  \n",
       "mean     0.998841      0.995365    0.125145  \n",
       "std      0.034040      2.358767    0.331075  \n",
       "min      0.000000     -5.000000    0.000000  \n",
       "25%      1.000000      0.000000    0.000000  \n",
       "50%      1.000000      0.000000    0.000000  \n",
       "75%      1.000000      1.000000    0.000000  \n",
       "max      1.000000     15.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=2, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=2) # Define the split - into 2 folds \n",
    "kf.get_n_splits(x_train) # returns the number of splitting iterations in the cross-validator\n",
    "KFold(n_splits=2, random_state=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for train_index, test_index in kf.split(x_train):\n",
    " #X_train, X_test = x_train[train_index], x_test[test_index]\n",
    " #Y_train, Y_test = y_train[train_index], y_test[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       115\n",
      "           1       1.00      0.40      0.57        15\n",
      "\n",
      "    accuracy                           0.93       130\n",
      "   macro avg       0.96      0.70      0.77       130\n",
      "weighted avg       0.94      0.93      0.92       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC()\n",
    "model.fit(x_train, y_train)\n",
    "# print prediction results\n",
    "predictions = model.predict(x_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Apply SVM classifier  Algorithm and tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.893 total time=   0.0s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.893 total time=   0.0s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.901 total time=   0.0s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.900 total time=   0.0s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.967 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.942 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.934 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.893 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.884 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.893 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.901 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.892 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.942 total time=   0.0s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.925 total time=   0.0s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.992 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.967 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.967 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.967 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.959 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.959 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.909 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.884 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.884 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.892 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.942 total time=   0.0s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.925 total time=   0.0s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.992 total time=   0.0s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.975 total time=   0.0s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.967 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.959 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.934 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.934 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.975 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.959 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.934 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.975 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.942 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.884 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.884 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.892 total time=   0.0s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.942 total time=   0.0s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.925 total time=   0.0s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.983 total time=   0.0s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.975 total time=   0.0s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.967 total time=   0.0s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.983 total time=   0.0s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.959 total time=   0.0s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.959 total time=   0.0s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.975 total time=   0.0s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.967 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.942 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.959 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.934 total time=   0.0s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.942 total time=   0.0s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.983 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.942 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['rbf']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "  \n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']} \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       115\n",
      "           1       1.00      0.60      0.75        15\n",
      "\n",
      "    accuracy                           0.95       130\n",
      "   macro avg       0.98      0.80      0.86       130\n",
      "weighted avg       0.96      0.95      0.95       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_predictions = grid.predict(x_test)\n",
    "# print classification report\n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AYA\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 16 is smaller than n_iter=50. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       115\n",
      "           1       1.00      0.40      0.57        15\n",
      "\n",
      "    accuracy                           0.93       130\n",
      "   macro avg       0.96      0.70      0.77       130\n",
      "weighted avg       0.94      0.93      0.92       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "          'rbf_svm__C': [1, 10, 100, 1000], \n",
    "          'rbf_svm__gamma': [0.001, 0.0001], \n",
    "          'rbf_svm__kernel': ['rbf', 'linear'],\n",
    "}\n",
    "# create pipeline with a scaler \n",
    "steps = [('scaler', StandardScaler()), ('rbf_svm', SVC())]\n",
    "pipeline = Pipeline(steps)\n",
    "# do search\n",
    "search = RandomizedSearchCV(pipeline, \n",
    "param_distributions=param_dist, n_iter=50)\n",
    "search.fit(x_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.plot_train_cv_test(x_train, y_train, x_cv, y_cv, x_test, y_test, title=\"input vs. target\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MultiLayer**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [               \n",
    "        tf.keras.Input(shape=(400,)),    #specify input size\n",
    "        ### START CODE HERE ### \n",
    "        Dense(units=25, activation='relu'), Dense(units=15, activation='relu'), Dense(units=1, activation='sigmoid')\n",
    "        \n",
    "        \n",
    "        ### END CODE HERE ### \n",
    "    ], name = \"my_model\" \n",
    ")                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AYA\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:402: UserWarning: X has feature names, but PolynomialFeatures was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\AYA\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:402: UserWarning: X has feature names, but PolynomialFeatures was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Add polynomial features\n",
    "degree = 1\n",
    "poly = PolynomialFeatures(degree, include_bias=False)\n",
    "X_train_mapped = poly.fit_transform(x_train)\n",
    "X_cv_mapped = poly.transform(x_cv)\n",
    "X_test_mapped = poly.transform(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN**\n",
    "\n",
    "supervised learning algorithm \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to predict using the cross-validation dataset and calculate the accuracy between the expected output and the original output by random number of neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[113   2]\n",
      " [ 11   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.95       115\n",
      "           1       0.67      0.27      0.38        15\n",
      "\n",
      "    accuracy                           0.90       130\n",
      "   macro avg       0.79      0.62      0.66       130\n",
      "weighted avg       0.88      0.90      0.88       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# acc=np.zeros(20)\n",
    "# #compare with validation data set to make sure of it\n",
    "# # matrix=confusion_matrix(y_cv,y_prediction)\n",
    "# # print(matrix)\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# x_train = scaler.fit_transform(x_train)\n",
    "# x_test = scaler.transform(x_test)\n",
    "# for i in range(1,21):\n",
    "#     #Train Model and Predict  \n",
    "#     knn = KNeighborsClassifier(n_neighbors = i).fit(x_train,y_train)\n",
    "#     yhat= knn.predict(x_cv)\n",
    "#     acc[i-1] = metrics.accuracy_score(y_cv, yhat)\n",
    "\n",
    "# acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we define a range of k values from 1 to 30, and we use 10-fold cross-validation to evaluate the accuracy of the model for each value of k. We store the cross-validation scores in a list, and we find the optimal k by selecting the value that gives the highest cross-validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86885246 0.8852459  0.86885246 0.8852459  0.88333333 0.88333333\n",
      " 0.88333333 0.88333333 0.88333333 0.86666667]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "neighbors=[]\n",
    "k_range=range(1,31)\n",
    "cv_scores=[]\n",
    "for k in k_range:\n",
    "    neighbors.append(k)\n",
    "    knn2=KNeighborsClassifier ( n_neighbors=k)\n",
    "    scores=cross_val_score(knn,x_train,y_train,cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "    \n",
    "\n",
    "scores=cross_val_score(knn2,x_train,y_train,cv=10, scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The optimal number of neigbors is 1 \n"
     ]
    }
   ],
   "source": [
    "optimal_k=k_range[np.argmax(cv_scores)]\n",
    "print(f\" The optimal number of neigbors is {optimal_k} \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we tried to determine the best k using the MeanSquared Error by finding the k that gives the minimum MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "MSE=[1-x for x in cv_scores]\n",
    "\n",
    "optimal_k =neighbors[MSE.index(min(MSE))]\n",
    "print(optimal_k)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(neighbors,MSE)\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Missclassification error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114   1]\n",
      " [  5  10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       115\n",
      "           1       0.91      0.67      0.77        15\n",
      "\n",
      "    accuracy                           0.95       130\n",
      "   macro avg       0.93      0.83      0.87       130\n",
      "weighted avg       0.95      0.95      0.95       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1, algorithm = 'brute')\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tunning hyperparameter k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'metric': 'manhattan', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "Test set accuracy: 0.9384615384615385\n"
     ]
    }
   ],
   "source": [
    "knn3 = KNeighborsClassifier()\n",
    "\n",
    "# Set the hyperparameters to tune over\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9, 11], 'weights': ['uniform', 'distance'], 'metric' : ['minkowski','euclidean','manhattan']}\n",
    "\n",
    "# Create a grid search object to find the best hyperparameters\n",
    "grid_search = GridSearchCV(knn3, param_grid, cv=5)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the model with the best hyperparameters on the test data\n",
    "print(\"Test set accuracy:\", grid_search.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
